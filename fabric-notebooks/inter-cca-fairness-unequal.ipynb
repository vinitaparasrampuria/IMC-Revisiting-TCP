{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02a5be90-977a-4948-a299-b5df71273eef",
   "metadata": {},
   "source": [
    "# Experiment to observe \"Intra-CCA fairness by Reno, Cubic and BBR at Edge and Core Scale containing unequal number of flows\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d083f0-5028-4517-8d4e-eba13f28cac4",
   "metadata": {},
   "source": [
    "## Set up your FABRIC environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf58277-480d-4459-a9c6-08a085b1313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "fablib = fablib_manager() \n",
    "fablib.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a288b3d-4162-4249-8c9a-111ddb4beecf",
   "metadata": {},
   "source": [
    "## Get slice details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7704d48-a158-4c40-ba58-9ea4f462706c",
   "metadata": {},
   "source": [
    "Put your slice name and the number of endpoints in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3047eaf-4fb4-40c1-8dd0-c2f364685384",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_endpoints = 10\n",
    "slice_name=\"bottleneck-\" + str(n_endpoints) + '-test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832e8f83-c35a-4669-98b5-647ef965efb1",
   "metadata": {},
   "source": [
    "Then, load your slice details into the environment.slice = fablib.new_slice(name=slice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9af4c-28f9-4314-8791-878b4c41d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac3a090-f28c-4665-a470-06a9967decac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_nodes = [slice.get_node(name='sender-' + str(i))  for i in range(n_endpoints)]\n",
    "receiver_nodes = [slice.get_node(name='receiver-' + str(i))  for i in range(n_endpoints)]\n",
    "router_node = slice.get_node(name='router')\n",
    "router_ingress_iface = router_node.get_interface(network_name = \"link-sender\")\n",
    "router_egress_iface  = router_node.get_interface(network_name = \"link-receiver\")\n",
    "router_egress_name = router_egress_iface.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c15e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in sender_nodes:\n",
    "    n.upload_file('iperf-parallel-senders.sh','iperf-parallel-senders.sh')\n",
    "for n in receiver_nodes:\n",
    "    n.upload_file('iperf-parallel-servers.sh','iperf-parallel-servers.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43392b9f-43fc-4f4a-9734-f63bc99a882f",
   "metadata": {},
   "source": [
    "## Generate flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a55ca7d-058b-4974-ba1e-47c074d9f50e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set experiment parameters\n",
    "\n",
    ">delay, cca, test_duration, num_servers, flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b034aa90-b05f-4b1f-93d7-c7475100a6cb",
   "metadata": {},
   "source": [
    "delay is the delay to be set at the receiver (20 ms,100 ms,200 ms)\n",
    "\n",
    "num_servers is the number of ports to be opened on each receiver. For core scale we are opening 10 ports and for edge scale we are opening 1 port\n",
    "\n",
    "test_duration is the time for which to send the iperf3 flows\n",
    "\n",
    "cca1 is the first congestion control algorithm (bbr, reno or cubic); cca2 is the second congestion control algorithm (bbr, reno or cubic)\n",
    "\n",
    "flows is the number of parallel flows to be send from each port\n",
    "\n",
    "For sending 1000 flows set num_servers=10 and flows=10. This will send 100 flows from each of the 10 senders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba875fc8-39b8-4cd2-a677-6ec5eb2f5643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cca1=\"bbr\"\n",
    "# cca2=\"reno\"\n",
    "# delay=20\n",
    "# test_duration=60\n",
    "# num_servers=10\n",
    "# flows=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b7d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate full factorial experiment\n",
    "\n",
    "import itertools\n",
    "exp_factors_core = {\n",
    "    'scenario': ['core'], \n",
    "    'rate': ['10Gbit'],\n",
    "    'limit': ['375MB'],\n",
    "    'cca': [\"bbr-reno\",\"bbr-cubic\"],\n",
    "    'delay': [20,100,200],\n",
    "    'test_duration': [300],\n",
    "    'num_servers': [300, 500, 700],\n",
    "    'flows': [1],\n",
    "    'interval': [0.01],\n",
    "    'omit': [0],\n",
    "    'trial': [1]\n",
    "}\n",
    "\n",
    "factor_names = [k for k in exp_factors_core]\n",
    "factor_lists = list(itertools.product(*exp_factors_core.values()))\n",
    "exp_lists_core = [dict(zip(factor_names, factor_l)) for factor_l in factor_lists]\n",
    "\n",
    "exp_factors_edge = { \n",
    "    'scenario': ['edge'], \n",
    "    'rate': ['100Mbit'],\n",
    "    'limit': ['3MB'],\n",
    "    'cca': [\"bbr-reno\",\"bbr-cubic\"],\n",
    "    'delay': [20,100,200],\n",
    "    'test_duration': [300],\n",
    "    'num_servers': [3, 5,7],\n",
    "    'flows': [1],\n",
    "    'interval': [0.01],\n",
    "    'omit': [0],\n",
    "    'trial': [1]\n",
    "}\n",
    "factor_names = [k for k in exp_factors_edge]\n",
    "factor_lists = list(itertools.product(*exp_factors_edge.values()))\n",
    "exp_lists_edge = [dict(zip(factor_names, factor_l)) for factor_l in factor_lists]\n",
    "\n",
    "exp_factors_inter = { \n",
    "    'scenario': ['inter'], \n",
    "    'rate': ['1Gbit'],\n",
    "    'limit': ['25MB'],\n",
    "    'cca': [\"bbr-reno\",\"bbr-cubic\"],\n",
    "    'delay': [20,100,200],\n",
    "    'test_duration': [1800],\n",
    "    'num_servers': [30, 50, 70],\n",
    "    'flows': [1],\n",
    "    'interval': [0.01],\n",
    "    'omit': [0],\n",
    "    'trial': [1]\n",
    "}\n",
    "\n",
    "factor_names = [k for k in exp_factors_edge]\n",
    "factor_lists = list(itertools.product(*exp_factors_inter.values()))\n",
    "exp_lists_inter = [dict(zip(factor_names, factor_l)) for factor_l in factor_lists]\n",
    "\n",
    "\n",
    "exp_lists = exp_lists_core + exp_lists_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5387bc6",
   "metadata": {},
   "source": [
    "# Start the experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67478d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory_name = \"intercca-unequal\"\n",
    "if not os.path.exists(directory_name):\n",
    "    # Create the directory\n",
    "    os.mkdir(directory_name)\n",
    "    print(f\"Directory '{directory_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Directory '{directory_name}' already exists.\")\n",
    "current_working_directory = os.getcwd()\n",
    "data_dir = os.path.join(current_working_directory, directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the base port to start the connections \n",
    "base_port=50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f3f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for exp in exp_lists: \n",
    "    # check if we already ran this experiment\n",
    "    # (allow stop/resume)\n",
    "    exp_name_str = \"_\".join( [str(v) for v in exp.values()] )\n",
    "    iunequal_file_out = data_dir + '/unequal_' + \"_\".join( [str(v) for v in exp.values()] )+ \".csv\" # file with throughput saved\n",
    "\n",
    "    # TODO check if the c file and j file already exist\n",
    "    if (os.path.exists(iunequal_file_out)):\n",
    "        print(\"Already have \" + iunequal_file_out + \", skipping\")\n",
    "\n",
    "    else:\n",
    "        print(\"Running experiment to generate \" +  iunequal_file_out)\n",
    "        \n",
    "        # set up edge or core scale setting\n",
    "        # first delete any existing queue\n",
    "        router_node.execute(\"sudo tc qdisc del dev \" + router_egress_name + \" root\")\n",
    "        # then set one up with HW offload\n",
    "        router_node.execute(\"sudo tc qdisc replace dev \" + router_egress_name + \" root handle 1: htb default 3 offload\")\n",
    "        router_node.execute(\"sudo tc class add dev \" + router_egress_name + \" parent 1: classid 1:3 htb rate \" + exp['rate'])\n",
    "        router_node.execute(\"sudo tc qdisc add dev \" + router_egress_name + \" parent 1:3 handle 3: bfifo limit \" + exp['limit'])\n",
    "\n",
    "        ## Remove existing result files from the hosts #Check if the files are removed from the senders and receivers\n",
    "        for n in receiver_nodes:\n",
    "            #n.execute(\"rm -f 60*\")\n",
    "            #n.execute(\"rm -f ./*\")\n",
    "            n.execute(\"rm -f server*\")\n",
    "\n",
    "        for n in sender_nodes:\n",
    "            #n.execute(\"rm -f ./*\")\n",
    "            #n.execute(\"rm -f 60*\")\n",
    "            n.execute(\"rm -f sender*\")\n",
    "            #n.execute(\"rm -f data*\")\n",
    "            #n.execute(\"rm -f packet*\")\n",
    "            #n.execute(\"rm -f output*\")\n",
    "\n",
    "        #Now set up delay on the receiver interface:\n",
    "        #First delete any existing queue (don't worry if there is an error, it means there was not!)\n",
    "        for n in receiver_nodes:\n",
    "            receiver_inf=n.get_interface(network_name= \"link-receiver\")\n",
    "            receiver_inf_name = receiver_inf.get_device_name()\n",
    "            n.execute(\"sudo tc qdisc del dev \" + receiver_inf_name + \" root netem\")\n",
    "            n.execute(\"sudo tc qdisc add dev \" + receiver_inf_name + \" root netem delay \" + str(exp['delay']) +\"ms limit 1000000\")\n",
    "\n",
    "        ### Start parallel servers on the receivers\n",
    "        #In this, the base_port is the starting address of port number\n",
    "        \n",
    "        print(\"Start parallel servers on the receivers\")\n",
    "        for i, n in enumerate(receiver_nodes):\n",
    "            n.execute(\"sudo killall iperf3\")\n",
    "            n.execute_thread(f'chmod +x iperf-parallel-servers.sh && bash iperf-parallel-servers.sh '+str(exp['num_servers']+1)+\" \"+str(base_port))\n",
    "        \n",
    "\n",
    "        ### Start parallel clients on the senders\n",
    "        #base_port=60000\n",
    "        \n",
    "        print(\"Start parallel clients on the senders\")\n",
    "        for i,n in enumerate(sender_nodes):\n",
    "            n.execute(\"sudo killall iperf3\")\n",
    "            n.execute_thread(f'chmod +x iperf-parallel-senders.sh && bash iperf-parallel-senders.sh 10.10.2.1'+str(i)+\" \"+str(exp['num_servers'])+\" \"+str(exp['test_duration'])+\" \"+exp['cca'].split(\"-\")[1]+\" \"+str(exp['flows'])+\" \"+str(exp['interval'])+\" \"+str(exp['omit'])+\" \"+str(base_port))\n",
    "            \n",
    "            if i==9:\n",
    "                n.execute(f'chmod +x iperf-parallel-senders.sh && bash iperf-parallel-senders.sh 10.10.2.1'+str(i)+\" 1 \"+str(exp['test_duration'])+\" \"+exp['cca'].split(\"-\")[0]+\" 1 \"+str(exp['interval'])+\" \"+str(exp['omit'])+\" \"+str(base_port+exp['num_servers']))\n",
    "\n",
    "        time.sleep(exp['test_duration']+180)\n",
    "\n",
    "        # Code for files to be saved/copied inside the sender \n",
    "        exp_dir = \"intercca-unequal/\" + \"_\".join( [str(v) for v in exp.values()])\n",
    "        for i,n in enumerate(sender_nodes):    \n",
    "            n.execute(f'mkdir -p {exp_dir} && cp sender* {exp_dir}/')\n",
    "        \n",
    "\n",
    "        ## Analyze the results\n",
    "        # Transfer files from hosts to router\n",
    "        # Calculate sum of bandwidth, square of sum of bandwidth, count of flows and jfi:\n",
    "\n",
    "        sum_bw1 = []\n",
    "        count_flow1 = []\n",
    "        sum_bw2 = []\n",
    "        count_flow2 = []\n",
    "\n",
    "        for i,n in enumerate(sender_nodes):\n",
    "            (sum_sen1, serr1)=n.execute(\"grep -r -E \\\"[0-9].*0.00-[0-9].*sender\\\" --include \\\"*\"+str(exp['test_duration'])+\"-\"+exp['cca'].split(\"-\")[1]+\".txt\\\" --exclude-dir=\\\"*int*\\\"  . |awk '{sum+=$7}END {print sum}'\")  \n",
    "            sum_bw1.append(float(sum_sen1.strip()))\n",
    "            (ncount1,ncerr1)=n.execute(\"grep -r -E \\\"[0-9].*0.00-[0-9].*sender\\\" --include \\*\"+exp['cca'].split(\"-\")[1]+\".txt --exclude-dir=\\\"*int*\\\" . |awk '{count+=1}END {print count}'\")\n",
    "            count_flow1.append(int(ncount1.strip()))\n",
    "            if i==9:\n",
    "                (sum_sen2, serr2)=n.execute(\"grep -r -E \\\"[0-9].*0.00-[0-9].*sender\\\" --include \\\"*\"+str(exp['test_duration'])+\"-\"+exp['cca'].split(\"-\")[1]+\".txt\\\" --exclude-dir=\\\"*int*\\\"  . |awk '{sum+=$7}END {print sum}'\")  \n",
    "                sum_bw2.append(float(sum_sen2.strip()))\n",
    "                (ncount2,ncerr2)=n.execute(\"grep -r -E \\\"[0-9].*0.00-[0-9].*sender\\\" --include \\*\"+exp['cca'].split(\"-\")[0]+\".txt --exclude-dir=\\\"*int*\\\" . |awk '{count+=1}END {print count}'\")\n",
    "                count_flow2.append(int(ncount2.strip()))\n",
    "\n",
    "        tput1=sum(sum_bw1)\n",
    "        c1=sum(count_flow1)\n",
    "        tput2=sum(sum_bw2)\n",
    "        c2=sum(count_flow2)\n",
    "        tp_share = (tput2*100)/(tput1 + tput2)\n",
    "\n",
    "        print(\"Experiment name \" + \"_\".join( [str(v) for v in exp.values()]))\n",
    "        print(\"Sum of bandwidth of \"+exp['cca'].split(\"-\")[0]+ \" is %f Kbits/sec \" % tput2)\n",
    "        print(\"Count of flows of \" +exp['cca'].split(\"-\")[0]+ \" is \" + str(c2))\n",
    "        print(\"Sum of bandwidth of \"+exp['cca'].split(\"-\")[1]+ \" is %f Kbits/sec \" % tput1)\n",
    "        print(\"Count of flows of \" +exp['cca'].split(\"-\")[1]+ \" is \" +  str(c1))\n",
    "        print(str(c2) + \" flows of \" + exp['cca'].split(\"-\")[0] +  \" has a throughput share of \" + str(tp_share) + \" against \" + str(c1)+  \" flows of \" + exp['cca'].split(\"-\")[1])       \n",
    "\n",
    "\n",
    "        if not os.path.isfile(iunequal_file_out):\n",
    "            with open(iunequal_file_out, 'a', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                header ='cca1', 'Number of flows of cca1', 'cca2', 'Number of flows of cca2', 'rtt', 'throughput_percentage_share'\n",
    "                writer.writerow(header)\n",
    "\n",
    "        with open(iunequal_file_out, 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            columns = exp['cca'].split(\"-\")[0], c2, exp['cca'].split(\"-\")[1], c1, exp['delay'], tp_share\n",
    "            writer.writerow(columns)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d982f36-1870-4caa-a89d-bef2fcbb0db2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fig 6 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plots \n",
    "\n",
    "# Fig 6\n",
    "# Core scale \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "N = 3\n",
    "ind = np.arange(N) \n",
    "width = 0.25\n",
    "color_name = {'20':'royalblue', '100':'tomato', '200':'mediumspringgreen'}\n",
    "xvals = [0,0,0]\n",
    "bar = [0,0,0]\n",
    "\n",
    "directory_name = \"intercca-unequal\"\n",
    "current_working_directory = os.getcwd()\n",
    "data_dir = os.path.join(current_working_directory, directory_name)\n",
    "\n",
    "# List of filenames for core and edge \n",
    "iunequal_files_core = [data_dir + '/unequal_' + \"_\".join( [str(v) for v in exp.values()] )+\".csv\" for exp in exp_lists_core] # file with JFI\n",
    "iunequal_files_edge = [data_dir + '/unequal_' + \"_\".join( [str(v) for v in exp.values()] )+\".csv\" for exp in exp_lists_edge] # file with JFI\n",
    "\n",
    "\n",
    "#  First let us plot for Core \n",
    "#Read each CSV file and append its DataFrame to the list and concatenate it later\n",
    "dfs = []\n",
    "for filename in iunequal_files_core:\n",
    "    df  = pd.read_csv(filename, header=0, names=['cca1', 'cca2', 'rtt', 'number_of_flows', 'throughput_percentage'])\n",
    "    dfs.append(df)  \n",
    "iunequal_dat_core = pd.concat(dfs, ignore_index=True) \n",
    "\n",
    "\n",
    "## Figure 6\n",
    "with PdfPages(\"Fig6_Core.pdf\") as pdf:  \n",
    "    plt.rcParams['figure.figsize'] = (5,3)\n",
    "    plt.rcParams['axes.axisbelow'] = True\n",
    "    plt.grid(axis='y')\n",
    "    dat_cca=iunequal_dat_core[(iunequal_dat_core['cca1'] == 'bbr') and (iunequal_dat_core['cca2'] == 'reno')]\n",
    "    dat_cca.sort_values(by=['number_of_flows'])\n",
    "    #print(dat_cca)\n",
    "    flows=pd.unique(dat_cca.number_of_flows)\n",
    "    rtt_num = pd.unique(dat_cca.rtt)       \n",
    "    for j,r in enumerate(rtt_num):\n",
    "        xvals[j] = dat_cca.throughput_percentage[dat_cca['rtt']==r]\n",
    "        bar[j] = plt.bar(ind + (width+0.02)*j, xvals[j], width, color = color_name[str(r)])\n",
    "\n",
    "    plt.xlabel(\"Flow Count\")\n",
    "    plt.ylabel('BBR Throughput(%)')\n",
    "    plt.title(\"Core Scale : BBR vs NewReno Unequal flows')        \n",
    "    plt.xticks(ind+width,flows)\n",
    "    plt.legend( (bar[j] for j in range(len(rtt_num))), (str(rtt_num[j]) + \" ms\" for j in range(len(rtt_num))), bbox_to_anchor=(1, 0.5), frameon=False )   \n",
    "    #pdf.savefig(bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "        \n",
    "#  Now let us plot for Edge \n",
    "#Read each CSV file and append its DataFrame to the list and concatenate it later\n",
    "\n",
    "dfs = []\n",
    "for filename in iunequal_files_edge:\n",
    "    df  = pd.read_csv(filename, header=0, names=['cca1', 'cca2', 'rtt', 'number_of_flows', 'throughput_percentage'])\n",
    "    dfs.append(df)  \n",
    "iunequal_dat_edge = pd.concat(dfs, ignore_index=True) \n",
    "\n",
    "with PdfPages(\"Fig6_Edge.pdf\") as pdf:  \n",
    "    plt.rcParams['figure.figsize'] = (5,3)\n",
    "    plt.rcParams['axes.axisbelow'] = True\n",
    "    plt.grid(axis='y')\n",
    "    dat_cca=iunequal_dat_edge[(iunequal_dat_edge['cca1'] == 'bbr') and (iunequal_dat_edge['cca2'] == 'reno')]\n",
    "    dat_cca.sort_values(by=['number_of_flows'])\n",
    "    #print(dat_cca)\n",
    "    flows=pd.unique(dat_cca.number_of_flows)\n",
    "    rtt_num = pd.unique(dat_cca.rtt)       \n",
    "    for j,r in enumerate(rtt_num):\n",
    "        xvals[j] = dat_cca.throughput_percentage[dat_cca['rtt']==r]\n",
    "        bar[j] = plt.bar(ind + (width+0.02)*j, xvals[j], width, color = color_name[str(r)])\n",
    "\n",
    "    plt.xlabel(\"Flow Count\")\n",
    "    plt.ylabel('BBR Throughput(%)')\n",
    "    plt.title(\"Edge Scale : BBR vs NewReno Unequal flows')        \n",
    "    plt.xticks(ind+width,flows)\n",
    "    plt.legend( (bar[j] for j in range(len(rtt_num))), (str(rtt_num[j]) + \" ms\" for j in range(len(rtt_num))), bbox_to_anchor=(1, 0.5), frameon=False )   \n",
    "    #pdf.savefig(bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff0631",
   "metadata": {},
   "source": [
    "## Fig 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53b12c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plots \n",
    "\n",
    "# Fig 6\n",
    "# Core scale \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "N = 3\n",
    "ind = np.arange(N) \n",
    "width = 0.25\n",
    "color_name = {'20':'royalblue', '100':'tomato', '200':'mediumspringgreen'}\n",
    "xvals = [0,0,0]\n",
    "bar = [0,0,0]\n",
    "\n",
    "directory_name = \"intercca-unequal\"\n",
    "current_working_directory = os.getcwd()\n",
    "data_dir = os.path.join(current_working_directory, directory_name)\n",
    "\n",
    "# List of filenames for core and edge \n",
    "iunequal_files_core = [data_dir + '/unequal_' + \"_\".join( [str(v) for v in exp.values()] )+\".csv\" for exp in exp_lists_core] # file with JFI\n",
    "iunequal_files_edge = [data_dir + '/unequal_' + \"_\".join( [str(v) for v in exp.values()] )+\".csv\" for exp in exp_lists_edge] # file with JFI\n",
    "\n",
    "\n",
    "#  First let us plot for Core \n",
    "#Read each CSV file and append its DataFrame to the list and concatenate it later\n",
    "dfs = []\n",
    "for filename in iunequal_files_core:\n",
    "    df  = pd.read_csv(filename, header=0, names=['cca1', 'cca2', 'rtt', 'number_of_flows', 'throughput_percentage'])\n",
    "    dfs.append(df)  \n",
    "iunequal_dat_core = pd.concat(dfs, ignore_index=True) \n",
    "\n",
    "\n",
    "## Figure 5\n",
    "with PdfPages(\"Fig7_Core.pdf\") as pdf:  \n",
    "    plt.rcParams['figure.figsize'] = (5,3)\n",
    "    plt.rcParams['axes.axisbelow'] = True\n",
    "    plt.grid(axis='y')\n",
    "    dat_cca=iunequal_dat_core[(iunequal_dat_core['cca1'] == 'bbr') and (iunequal_dat_core['cca2'] == 'cubic')]\n",
    "    dat_cca.sort_values(by=['number_of_flows'])\n",
    "    #print(dat_cca)\n",
    "    flows=pd.unique(dat_cca.number_of_flows)\n",
    "    rtt_num = pd.unique(dat_cca.rtt)       \n",
    "    for j,r in enumerate(rtt_num):\n",
    "        xvals[j] = dat_cca.throughput_percentage[dat_cca['rtt']==r]\n",
    "        bar[j] = plt.bar(ind + (width+0.02)*j, xvals[j], width, color = color_name[str(r)])\n",
    "\n",
    "    plt.xlabel(\"Flow Count\")\n",
    "    plt.ylabel('BBR Throughput(%)')\n",
    "    plt.title(\"Core Scale : BBR vs Cubic Unequal flows')        \n",
    "    plt.xticks(ind+width,flows)\n",
    "    plt.legend( (bar[j] for j in range(len(rtt_num))), (str(rtt_num[j]) + \" ms\" for j in range(len(rtt_num))), bbox_to_anchor=(1, 0.5), frameon=False )   \n",
    "    #pdf.savefig(bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "        \n",
    "#  Now let us plot for Edge \n",
    "#Read each CSV file and append its DataFrame to the list and concatenate it later\n",
    "\n",
    "dfs = []\n",
    "for filename in iunequal_files_edge:\n",
    "    df  = pd.read_csv(filename, header=0, names=['cca1', 'cca2', 'rtt', 'number_of_flows', 'throughput_percentage'])\n",
    "    dfs.append(df)  \n",
    "iunequal_dat_edge = pd.concat(dfs, ignore_index=True) \n",
    "\n",
    "with PdfPages(\"Fig7_Edge.pdf\") as pdf:  \n",
    "    plt.rcParams['figure.figsize'] = (5,3)\n",
    "    plt.rcParams['axes.axisbelow'] = True\n",
    "    plt.grid(axis='y')\n",
    "    dat_cca=iunequal_dat_edge[(iunequal_dat_edge['cca1'] == 'bbr') and (iunequal_dat_edge['cca2'] == 'cubic')]\n",
    "    dat_cca.sort_values(by=['number_of_flows'])\n",
    "    #print(dat_cca)\n",
    "    flows=pd.unique(dat_cca.number_of_flows)\n",
    "    rtt_num = pd.unique(dat_cca.rtt)       \n",
    "    for j,r in enumerate(rtt_num):\n",
    "        xvals[j] = dat_cca.throughput_percentage[dat_cca['rtt']==r]\n",
    "        bar[j] = plt.bar(ind + (width+0.02)*j, xvals[j], width, color = color_name[str(r)])\n",
    "\n",
    "    plt.xlabel(\"Flow Count\")\n",
    "    plt.ylabel('BBR Throughput(%)')\n",
    "    plt.title(\"Edge Scale : BBR vs Cubic Unequal flows')        \n",
    "    plt.xticks(ind+width,flows)\n",
    "    plt.legend( (bar[j] for j in range(len(rtt_num))), (str(rtt_num[j]) + \" ms\" for j in range(len(rtt_num))), bbox_to_anchor=(1, 0.5), frameon=False )   \n",
    "    #pdf.savefig(bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0da211-a87d-4dc1-b931-205b19fa3dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import sys\n",
    "# import os\n",
    "\n",
    "# jfi_filename='jfi.csv'\n",
    "# if not os.path.isfile(jfi_filename):\n",
    "#     with open(jfi_filename, 'a', newline='') as csvfile:\n",
    "#         writer = csv.writer(csvfile)\n",
    "#         # header ='CCA1', 'CCA2', 'Duration of Expt(sec)', 'Base RTT(ms)', 'Total Bandwidth(Kbps)', 'BW_CCA1', 'BW_CCA2', 'Count_CCA1', 'Count_CCA2', 'BW_CCA1/BW'\n",
    "#         writer.writerow(header)\n",
    "    \n",
    "# with open(jfi_filename, 'a', newline='') as csvfile:\n",
    "#     writer = csv.writer(csvfile)\n",
    "#     columns = cca1, cca2, test_duration, delay, tput1+tput2, tput1, tput2, c1, c2, tput2/(tput1+tput2)\n",
    "#     writer.writerow(columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
